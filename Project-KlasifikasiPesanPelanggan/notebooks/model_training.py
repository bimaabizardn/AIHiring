# -*- coding: utf-8 -*-
"""model_training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10YyXG04hSYJguTvA-WU8a-L_HOIfamkf
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from imblearn.over_sampling import SMOTE
import pickle # Import pickle to potentially save the final model

# --- 1. Muat Data yang Sudah Dipreproses ---
# Pastikan file 'preprocessed_dataset_labeled.csv' berada di direktori yang sama.
try:
    df = pd.read_csv('/content/preprocessed_dataset_labeled.csv')
    print("Data berhasil dimuat.")
except FileNotFoundError:
    print("Error: File 'preprocessed_dataset_labeled.csv' tidak ditemukan.")
    exit()

# --- Check class distribution and handle classes with single members ---
# (Assuming this step was already done in the initial data loading cell and df is updated)
# If not, uncomment and run the class handling code again:
class_counts = df['label_encoded'].value_counts()
single_sample_classes = class_counts[class_counts == 1].index.tolist()
if single_sample_classes:
    df = df[~df['label_encoded'].isin(single_sample_classes)]
    print(f"\nMenghapus baris dengan kelas hanya memiliki 1 sampel: {single_sample_classes}")


# --- 2. Siapkan Data untuk Pelatihan Model ---
X = df['text']
y = df['label_encoded']

# Bagi data menjadi set pelatihan (training) dan set pengujian (testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print(f"\nJumlah data training: {len(X_train)}")
print(f"Jumlah data testing: {len(X_test)}")

# --- 3. Vektorisasi Teks dengan TF-IDF (dengan parameter terbaik) ---
# Use the best parameters found during TF-IDF tuning
# Assuming best_tfidf_params variable is available from previous execution
# If not, define it here based on the summary:
best_tfidf_params = {'max_df': 0.9, 'max_features': 1000, 'min_df': 1, 'ngram_range': (1, 2)}

optimized_tfidf_vectorizer = TfidfVectorizer(**best_tfidf_params)

X_train_tfidf_optimized = optimized_tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf_optimized = optimized_tfidf_vectorizer.transform(X_test)
print(f"\nShape of optimized TF-IDF matrix (training): {X_train_tfidf_optimized.shape}")

# --- 4. Penanganan Data Imbalance dengan SMOTE ---
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf_optimized, y_train)
print("\nClass distribution in resampled training data:")
print(y_train_resampled.value_counts())


# --- 5. Latih Model Random Forest (Model Terbaik) ---
best_model = RandomForestClassifier(random_state=42)
best_model.fit(X_train_resampled, y_train_resampled)
print("\nBest model (Random Forest) trained with resampled data and optimized TF-IDF features.")

# --- 6. Evaluasi Model Terbaik ---
y_pred_best = best_model.predict(X_test_tfidf_optimized)

# Tampilkan Classification Report
print("\nClassification Report for the Best Model:")
# Use remaining_labels from the initial data loading cell
remaining_labels = df['label'].unique()
print(classification_report(y_test, y_pred_best, target_names=remaining_labels))

# Tampilkan Akurasi
accuracy_best = accuracy_score(y_test, y_pred_best)
print(f"\nAccuracy of the Best Model: {accuracy_best:.4f}")

# --- Opsional: Simpan Model Terbaik dan Vectorizer ---
model_filename_best = 'best_text_classification_model.pkl'
vectorizer_filename_best = 'optimized_tfidf_vectorizer.pkl'

with open(model_filename_best, 'wb') as model_file:
    pickle.dump(best_model, model_file)
print(f"\nModel terbaik berhasil disimpan ke: {model_filename_best}")

with open(vectorizer_filename_best, 'wb') as vectorizer_file:
    pickle.dump(optimized_tfidf_vectorizer, vectorizer_file)
print(f"Vectorizer terbaik berhasil disimpan ke: {vectorizer_filename_best}")