{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Preprocessing Data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Notebook ini berisi langkah-langkah preprocessing data untuk dataset `dataset_labeled.csv`.\n",
                "Dataset ini memiliki format yang tidak konsisten, sehingga diperlukan parsing data secara manual."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "import pandas as pd\n",
                "import re\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "# --- 1. Data Loading dan Parsing ---\n",
                "# Muat data secara manual karena format file yang tidak konsisten.\n",
                "# File dibaca baris per baris, dan kolom dipisahkan menggunakan regex.\n",
                "\n",
                "try:\n",
                "    with open('dataset_labeled.csv', 'r') as file:\n",
                "        content = file.read()\n",
                "except FileNotFoundError:\n",
                "    print(\"File `dataset_labeled.csv` tidak ditemukan. Pastikan file berada di direktori yang sama.\")\n",
                "    # Exit or handle error gracefully\n",
                "\n",
                "pattern = re.compile(r'(?:\\s*\"(.*?)\",?|([^,]*),?)([^,]*),([\\d.]+)((?:.|\\s)*)')\n",
                "data_rows = []\n",
                "\n",
                "for line in content.strip().split('\\n')[1:]: # Lewati header\n",
                "    match = pattern.search(line)\n",
                "    if match:\n",
                "        text = match.group(1) if match.group(1) is not None else match.group(2)\n",
                "        label = match.group(3)\n",
                "        confidence = match.group(4)\n",
                "        data_rows.append([text, label, confidence])\n",
                "    else:\n",
                "        # Fallback for some specific malformed lines\n",
                "        parts = line.split(',')\n",
                "        if len(parts) >= 3:\n",
                "            text = parts[0]\n",
                "            label = parts[1]\n",
                "            confidence = parts[2]\n",
                "            data_rows.append([text, label, confidence])\n",
                "\n",
                "df = pd.DataFrame(data_rows, columns=['text', 'label', 'auto_label_confidence'])\n",
                "\n",
                "print(\"Shape data setelah parsing:\")\n",
                "print(df.shape)\n",
                "print(\"\\n5 baris pertama:\")\n",
                "print(df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Pembersihan Data\n",
                "Langkah-langkah pembersihan data yang dilakukan adalah sebagai berikut:\n",
                "1.  **Menghapus Duplikat**: Menghapus baris yang memiliki nilai duplikat untuk memastikan keunikan data.\n",
                "2.  **Konversi Tipe Data**: Mengubah tipe data kolom `auto_label_confidence` menjadi numerik.\n",
                "3.  **Pembersihan Teks**: Mengubah teks menjadi huruf kecil dan menghapus tanda kutip."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# --- 2. Data Cleaning ---\n",
                "# Menghapus baris duplikat\n",
                "initial_row_count = len(df)\n",
                "df.drop_duplicates(inplace=True)\n",
                "print(f\"Jumlah baris awal: {initial_row_count}\")\n",
                "print(f\"Jumlah baris setelah menghapus duplikat: {len(df)}\")\n",
                "\n",
                "# Mengubah tipe data kolom 'auto_label_confidence' menjadi numerik\n",
                "df['auto_label_confidence'] = pd.to_numeric(df['auto_label_confidence'], errors='coerce')\n",
                "\n",
                "# Mengubah teks menjadi huruf kecil dan menghapus tanda kutip\n",
                "df['text'] = df['text'].str.strip().str.lower().str.replace('^\"|\"$', '', regex=True)\n",
                "\n",
                "print(\"\\nInformasi DataFrame setelah pembersihan:\")\n",
                "print(df.info())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Transformasi Data\n",
                "Pada langkah ini, kolom `label` akan diubah dari data kategori menjadi numerik menggunakan `LabelEncoder`. Ini diperlukan untuk model machine learning yang hanya dapat memproses data numerik."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# --- 3. Data Transformation ---\n",
                "# Menggunakan LabelEncoder untuk mengkodekan kolom 'label'\n",
                "le = LabelEncoder()\n",
                "df['label_encoded'] = le.fit_transform(df['label'])\n",
                "\n",
                "print(\"Mapping Label ke Nilai Terkode:\")\n",
                "for label, encoded_value in zip(le.classes_, le.transform(le.classes_)):\n",
                "    print(f\"  {label}: {encoded_value}\")\n",
                "\n",
                "print(\"\\nDataFrame setelah transformasi:\")\n",
                "print(df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Menyimpan Hasil Preprocessing\n",
                "Data yang sudah bersih dan terstruktur disimpan ke dalam file CSV baru."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# --- 4. Save Preprocessed Data ---\n",
                "output_file_path = 'preprocessed_dataset_labeled.csv'\n",
                "df.to_csv(output_file_path, index=False)\n",
                "\n",
                "print(f\"\\nData preprocessing selesai dan disimpan ke dalam file: {output_file_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}